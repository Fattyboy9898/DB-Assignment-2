{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import IntegerType \n",
    "# you may add more import if you need to\n",
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "sc = SparkContext.getOrCreate()\n",
    "spark = SparkSession.builder.appName(\"Assigment 2 Question 5\").getOrCreate()\n",
    "# YOUR CODE GOES BELOW\n",
    "df = spark.read.parquet(\"./data/tmdb_5000_credits.parquet\")\n",
    "df =df.drop(\"crew\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn(\"cast\",F.split(df['cast'],'\\\\}, \\\\{\"cast_id\"'))\n",
    "df = df.withColumn(\"cast\",F.explode(\"cast\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "425071\n",
      "106279\n",
      "root\n",
      " |-- movie_id: long (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- cast: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def extractName(data):\n",
    "    print(data)\n",
    "    movie_id = data.movie_id\n",
    "    title = data.title\n",
    "    cast = data.cast\n",
    "    index = cast.find('\"name\"') + 9\n",
    "    cast = cast[index:]\n",
    "    cast = cast.strip()\n",
    "    return (movie_id,title,cast)\n",
    "\n",
    "\n",
    "df = df.withColumn(\"cast\",F.split(df['cast'],'\", \"'))\n",
    "df = df.withColumn(\"cast\",F.explode(\"cast\"))\n",
    "print(df.count())\n",
    "df = df.filter(F.col(\"cast\").contains(\"name\"))\n",
    "print(df.count())\n",
    "df.printSchema()\n",
    "rdd = df.rdd.map(lambda x: extractName(x))\n",
    "df = spark.createDataFrame(rdd).toDF(\"movie_id\",\"title\",\"actor\")\n",
    "df = df.sort(\"actor\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+--------------------+\n",
      "|movie_id|               title| collect_list(actor)|\n",
      "+--------+--------------------+--------------------+\n",
      "|       5|          Four Rooms|[Alicia Witt, Ama...|\n",
      "|      11|           Star Wars|[Al Lampert, Alan...|\n",
      "|      12|        Finding Nemo|[Albert Brooks, A...|\n",
      "|      13|        Forrest Gump|[Aaron Michael La...|\n",
      "|      14|     American Beauty|[Elaine Corral Ke...|\n",
      "|      16|  Dancer in the Dark|[Al Agami, Anna N...|\n",
      "|      18|   The Fifth Element|[Eddie Ellwood, F...|\n",
      "|      19|          Metropolis|[Alfred Abel, Art...|\n",
      "|      20|  My Life Without Me|[Alfred Molina, A...|\n",
      "|      22|Pirates of the Ca...|[Angus Barnett, A...|\n",
      "|      24|   Kill Bill: Vol. 1|[Ai Maeda, Akaji ...|\n",
      "|      25|             Jarhead|[Brian Geraghty, ...|\n",
      "|      28|      Apocalypse Now|[Albert Hall, Aur...|\n",
      "|      33|          Unforgiven|[Anna Levine, Ant...|\n",
      "|      35|  The Simpsons Movie|[Albert Brooks, B...|\n",
      "|      38|Eternal Sunshine ...|[Amir Ali Said, B...|\n",
      "|      55|       Amores perros|[Adriana Barraza,...|\n",
      "|      58|Pirates of the Ca...|[Alex Norton, And...|\n",
      "|      59|A History of Viol...|[Aidan Devine, As...|\n",
      "|      62|2001: A Space Ody...|[Alan Gifford, An...|\n",
      "+--------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def countMovies(data):\n",
    "    actor = data.actor\n",
    "    title = data['collect_list(title)']\n",
    "    movie_id = data['collect_list(movie_id)']\n",
    "    c = len(movie_id)\n",
    "    return (actor,title,movie_id,c)\n",
    "df2 = df.groupBy('movie_id','title').agg(F.collect_list('actor')).sort('movie_id')\n",
    "df2.show()\n",
    "#df = df.groupBy('actor').agg(F.collect_list('title'),F.collect_list('movie_id'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+-----------------+\n",
      "|movie_id|     title|            actor|\n",
      "+--------+----------+-----------------+\n",
      "|       5|Four Rooms|      Alicia Witt|\n",
      "|       5|Four Rooms|Amanda de Cadenet|\n",
      "|       5|Four Rooms| Antonio Banderas|\n",
      "|       5|Four Rooms|     Bruce Willis|\n",
      "|       5|Four Rooms|   Danny Verduzco|\n",
      "|       5|Four Rooms|     David Proval|\n",
      "|       5|Four Rooms|        Ione Skye|\n",
      "|       5|Four Rooms|   Jennifer Beals|\n",
      "|       5|Four Rooms|    Kathy Griffin|\n",
      "|       5|Four Rooms|   Kimberly Blair|\n",
      "|       5|Four Rooms|   Lana McKissack|\n",
      "|       5|Four Rooms|  Lawrence Bender|\n",
      "|       5|Four Rooms|      Lili Taylor|\n",
      "|       5|Four Rooms|          Madonna|\n",
      "|       5|Four Rooms|    Marc Lawrence|\n",
      "|       5|Four Rooms|     Marisa Tomei|\n",
      "|       5|Four Rooms|   Patricia Vonne|\n",
      "|       5|Four Rooms|    Paul Calderon|\n",
      "|       5|Four Rooms|Quentin Tarantino|\n",
      "|       5|Four Rooms|      Salma Hayek|\n",
      "+--------+----------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2 = df2.select('movie_id','title',F.explode('collect_list(actor)').alias('actor'))\n",
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "106279"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "106095"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = df2.distinct()\n",
    "df2.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df2.alias('df3')\n",
    "df4 = df2.alias('df4')\n",
    "df3 = df3.withColumnRenamed(\"actor\",\"actor1\")\n",
    "df4 = df4.withColumnRenamed(\"actor\",\"actor2\")\n",
    "\n",
    "dfForJoining = df3.join(df4,[F.col(\"df3.movie_id\")==F.col(\"df4.movie_id\"),F.col(\"actor1\")<F.col(\"actor2\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df =dfForJoining.groupBy(\"actor1\",\"actor2\").agg(F.count(\"df3.movie_id\"))\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.filter(df[\"`count(df3.movie_id)`\"]>1)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfForJoining = dfForJoining.select(\"df3.movie_id\",\"df3.title\",\"actor1\",\"actor2\")\n",
    "dfForJoining = dfForJoining.withColumnRenamed(\"actor1\",\"joinActor1\")\n",
    "dfForJoining = dfForJoining.withColumnRenamed(\"actor2\",\"joinActor2\")\n",
    "\n",
    "df = df.join(dfForJoining,[F.col(\"actor1\")==F.col(\"joinActor1\"),F.col(\"actor2\")==F.col(\"joinActor2\")])\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.select('movie_id','title','actor1','actor2')\n",
    "df.show()\n",
    "print(df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.\nA suitable version of pyarrow or fastparquet is required for parquet support.\nTrying to import the above resulted in these errors:\n - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.\n - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-68-2ab3d6df1c79>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#df.toPandas().to_csv(\"output/modifiedData5.csv\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoPandas\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_parquet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"output/modifiedData5.parquet\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    197\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mto_parquet\u001b[1;34m(self, path, engine, compression, index, partition_cols, storage_options, **kwargs)\u001b[0m\n\u001b[0;32m   2453\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparquet\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mto_parquet\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2454\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2455\u001b[1;33m         return to_parquet(\n\u001b[0m\u001b[0;32m   2456\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2457\u001b[0m             \u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\io\\parquet.py\u001b[0m in \u001b[0;36mto_parquet\u001b[1;34m(df, path, engine, compression, index, storage_options, partition_cols, **kwargs)\u001b[0m\n\u001b[0;32m    384\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpartition_cols\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    385\u001b[0m         \u001b[0mpartition_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mpartition_cols\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 386\u001b[1;33m     \u001b[0mimpl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    387\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    388\u001b[0m     \u001b[0mpath_or_buf\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mFilePathOrBuffer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mpath\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\io\\parquet.py\u001b[0m in \u001b[0;36mget_engine\u001b[1;34m(engine)\u001b[0m\n\u001b[0;32m     34\u001b[0m                 \u001b[0merror_msgs\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;34m\"\\n - \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m         raise ImportError(\n\u001b[0m\u001b[0;32m     37\u001b[0m             \u001b[1;34m\"Unable to find a usable engine; \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m             \u001b[1;34m\"tried using: 'pyarrow', 'fastparquet'.\\n\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.\nA suitable version of pyarrow or fastparquet is required for parquet support.\nTrying to import the above resulted in these errors:\n - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.\n - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet."
     ]
    }
   ],
   "source": [
    "#df.toPandas().to_csv(\"output/modifiedData5.csv\")\n",
    "df.toPandas().to_parquet(\"output/modifiedData5.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.write.parquet(\"output/modifiedData5.parquet\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "df67e98752399f1df19cca3c6bce828e5600fc8fe66d1d5fce4520b14f4d0349"
  },
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
